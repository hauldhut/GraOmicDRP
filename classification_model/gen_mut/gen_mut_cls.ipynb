{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gen_mut_cls.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"A8RAxOyOt9_S"},"source":["!pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install torch-geometric \\\n","  torch-sparse==latest+cu100 \\\n","  torch-scatter==latest+cu100 \\\n","  torch-cluster==latest+cu100 \\\n","  -f https://pytorch-geometric.com/whl/torch-1.4.0.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xt48ybrSve7_"},"source":["\n","import numpy as np\n","import pandas as pd\n","import sys, os\n","from random import shuffle\n","import torch\n","import torch.nn as nn\n","from models.gat import GATNet\n","from models.gat_gcn import GAT_GCN\n","from models.gcn import GCNNet\n","from models.ginconv import GINConvNet\n","from utils import *\n","import datetime\n","import argparse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7llZnTNgvfqV"},"source":["def set_parameter_requires_grad(model, feature_extracting=True):\n","  for param in model.parameters():\n","      param.requires_grad = not feature_extracting"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJI4nugavhx-"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import Sequential, Linear, ReLU\n","from torch_geometric.nn import GINConv, global_add_pool\n","from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n","\n","# GINConv model\n","class GINConvNet(torch.nn.Module):\n","    def __init__(self, n_output=1,num_features_xd=78, num_features_xt=25,\n","                 n_filters=32, embed_dim=128, output_dim=128, dropout=0.2):\n","\n","        super(GINConvNet, self).__init__()\n","\n","        dim = 32\n","        self.dropout = nn.Dropout(dropout)\n","        self.relu = nn.ReLU()\n","        self.n_output = n_output\n","        # convolution layers\n","        nn1 = Sequential(Linear(num_features_xd, dim), ReLU(), Linear(dim, dim))\n","        self.conv1 = GINConv(nn1)\n","        self.bn1 = torch.nn.BatchNorm1d(dim)\n","\n","        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv2 = GINConv(nn2)\n","        self.bn2 = torch.nn.BatchNorm1d(dim)\n","\n","        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv3 = GINConv(nn3)\n","        self.bn3 = torch.nn.BatchNorm1d(dim)\n","\n","        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv4 = GINConv(nn4)\n","        self.bn4 = torch.nn.BatchNorm1d(dim)\n","\n","        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv5 = GINConv(nn5)\n","        self.bn5 = torch.nn.BatchNorm1d(dim)\n","\n","        self.fc1_xd = Linear(dim, output_dim)\n","\n","        # 1D convolution on protein sequence  # mut features\n","        self.embedding_xt_mut = nn.Embedding(num_features_xt + 1, embed_dim)\n","        self.conv_xt_mut_1 = nn.Conv1d(in_channels=1000, out_channels=n_filters, kernel_size=8)\n","\n","        # 1D convolution on protein sequence # mut features\n","        self.embedding_xt_meth = nn.Embedding(num_features_xt + 1, embed_dim)\n","        self.conv_xt_meth_1 = nn.Conv1d(in_channels=1000, out_channels=n_filters, kernel_size=8)\n","\n","\n","        # cell line mut feature\n","        self.conv_xt_mut_1 = nn.Conv1d(in_channels=1, out_channels=n_filters, kernel_size=8)\n","        self.pool_xt_mut_1 = nn.MaxPool1d(3)\n","        self.conv_xt_mut_2 = nn.Conv1d(in_channels=n_filters, out_channels=n_filters*2, kernel_size=8)\n","        self.pool_xt_mut_2 = nn.MaxPool1d(3)\n","        self.conv_xt_mut_3 = nn.Conv1d(in_channels=n_filters*2, out_channels=n_filters*4, kernel_size=8)\n","        self.pool_xt_mut_3 = nn.MaxPool1d(3)\n","        self.fc1_xt_mut = nn.Linear(2944, output_dim)\n","        # self.fc1_xt_mut = nn.Linear(1280, output_dim)\n","\n","\n","\n","        # cell line meth feature\n","        self.conv_xt_meth_1 = nn.Conv1d(in_channels=1, out_channels=n_filters, kernel_size=8)\n","        self.pool_xt_meth_1 = nn.MaxPool1d(3)\n","        self.conv_xt_meth_2 = nn.Conv1d(in_channels=n_filters, out_channels=n_filters*2, kernel_size=8)\n","        self.pool_xt_meth_2 = nn.MaxPool1d(3)\n","        self.conv_xt_meth_3 = nn.Conv1d(in_channels=n_filters*2, out_channels=n_filters*4, kernel_size=8)\n","        self.pool_xt_meth_3 = nn.MaxPool1d(3)\n","        self.fc1_xt_meth = nn.Linear(83584, output_dim)\n","\n","        # combined layers\n","        self.fc1 = nn.Linear(3*output_dim, 1024)\n","        self.fc2 = nn.Linear(1024, 128)\n","        self.out = nn.Linear(128, n_output)\n","\n","        # activation and regularization\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        #print(x)\n","        #print(data.target)\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = self.bn1(x)\n","        x = F.relu(self.conv2(x, edge_index))\n","        x = self.bn2(x)\n","        x = F.relu(self.conv3(x, edge_index))\n","        x = self.bn3(x)\n","        x = F.relu(self.conv4(x, edge_index))\n","        x = self.bn4(x)\n","        x = F.relu(self.conv5(x, edge_index))\n","        x = self.bn5(x)\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1_xd(x))\n","        x = F.dropout(x, p=0.2, training=self.training)\n","\n","        # protein input feed-forward:\n","        target_mut = data.target_mut\n","        #print(data.target_mut)\n","        #print(len(data.target_mut))\n","        #print(len(data.target_mut[1]))\n","        target_mut = target_mut[:,None,:]\n","\n","        # protein input feed-forward:\n","        target_meth = data.target_meth\n","        #print(data.target_meth)\n","        #print(len(data.target_meth))\n","        #print(len(data.target_meth[1]))\n","        target_meth = target_meth[:,None,:]\n","\n","\n","       \n","        # 1d conv layers xt_mut\n","        conv_xt_mut = self.conv_xt_mut_1(target_mut)\n","        conv_xt_mut = F.relu(conv_xt_mut)\n","        conv_xt_mut = self.pool_xt_mut_1(conv_xt_mut)\n","        conv_xt_mut = self.conv_xt_mut_2(conv_xt_mut)\n","        conv_xt_mut = F.relu(conv_xt_mut)\n","        conv_xt_mut = self.pool_xt_mut_2(conv_xt_mut)\n","        conv_xt_mut = self.conv_xt_mut_3(conv_xt_mut)\n","        conv_xt_mut = F.relu(conv_xt_mut)\n","        conv_xt_mut = self.pool_xt_mut_3(conv_xt_mut)\n","        \n","        # 1d conv layers\n","        conv_xt_meth = self.conv_xt_meth_1(target_meth)\n","        conv_xt_meth = F.relu(conv_xt_meth)\n","        conv_xt_meth = self.pool_xt_meth_1(conv_xt_meth)\n","        conv_xt_meth = self.conv_xt_meth_2(conv_xt_meth)\n","        conv_xt_meth = F.relu(conv_xt_meth)\n","        conv_xt_meth = self.pool_xt_meth_2(conv_xt_meth)\n","        conv_xt_meth = self.conv_xt_meth_3(conv_xt_meth)\n","        conv_xt_meth = F.relu(conv_xt_meth)\n","        conv_xt_meth = self.pool_xt_meth_3(conv_xt_meth)\n","\n","\n","        # flatten mut\n","        xt_mut = conv_xt_mut.view(-1, conv_xt_mut.shape[1] * conv_xt_mut.shape[2])\n","        xt_mut = self.fc1_xt_mut(xt_mut)\n","        #print(xt_mut)\n","        \n","        # flatten meth\n","        xt_meth = conv_xt_meth.view(-1, conv_xt_meth.shape[1] * conv_xt_meth.shape[2])\n","        xt_meth = self.fc1_xt_meth(xt_meth)\n","        #print(xt_meth)\n","        \n","\n","        # concat\n","        xc = torch.cat((x, xt_mut, xt_meth), 1)\n","        # add some dense layers\n","        xc = self.fc1(xc)\n","        xc = self.relu(xc)\n","        xc = self.dropout(xc)\n","        xc = self.fc2(xc)\n","        xc = self.relu(xc)\n","        xc = self.dropout(xc)\n","        out = self.out(xc)\n","        return out, x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQn72dDzvjOO","executionInfo":{"status":"ok","timestamp":1616043494991,"user_tz":-420,"elapsed":23981,"user":{"displayName":"Hòa Vũ Đức","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh_wJcXD22KPMqatwHABp3vSvm9X-kqs3M54sK=s64","userId":"16151263202855849236"}},"outputId":"99f86250-360a-4987-eb2b-45830e4fce39"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","n_class = 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rYRQIVaxvlX3"},"source":["modeling = GINConvNet\n","model = modeling().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"40HzQv7GV5dV"},"source":["model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbdDs5H2vmj5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616043498522,"user_tz":-420,"elapsed":27464,"user":{"displayName":"Hòa Vũ Đức","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh_wJcXD22KPMqatwHABp3vSvm9X-kqs3M54sK=s64","userId":"16151263202855849236"}},"outputId":"4871776a-5f82-4c57-d582-3570bdbf59c0"},"source":["model.load_state_dict(torch.load('/content/drive/MyDrive/05.New_DRP3_ge_meth/Pretrain_DRP/DRP_RS_ge_mut/model_GINconvNet_GDSC_ge_mut_new.model'))\n","# set_parameter_requires_grad(model)\n","# model.eval()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"ezHJiFkMvn5W"},"source":["model.out = nn.Sequential(nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, n_class), nn.Softmax())\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKKQXkjVvwG_"},"source":["feature_extract = True\n","params_to_update = model.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCkE7Qp3vxfx"},"source":["data_path = \"/content/drive/MyDrive/05.New_DRP3_ge_meth/recall_moli/create_data/Splitting_data_new/gen_mut/\"\n","data_processed_path = \"/content/drive/MyDrive/05.New_DRP3_ge_meth/recall_moli/create_data/Splitting_data_new/gen_mut/processed/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCiNRmDeUe05"},"source":["model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNN6Ko0dNN6r"},"source":["from sklearn.metrics import roc_auc_score\n","def roc_auc_compute_fn(y_preds: torch.Tensor, y_targets: torch.Tensor) -> float:\n","    y_true = y_targets.numpy()\n","    y_pred = y_preds.numpy()\n","    return roc_auc_score(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9MIZrV7vy3l"},"source":["# training function at each epoch\n","def train(model, device, train_loader, optimizer, epoch, log_interval):\n","    print('Training on {} samples...'.format(len(train_loader.dataset)))\n","    model.train()\n","    loss_fn = nn.BCELoss()\n","    avg_loss = []\n","    for batch_idx, data in enumerate(train_loader):\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output, _ = model(data)\n","        loss = loss_fn(output, data.y.view(-1,2).float().to(device))\n","        loss.backward()\n","        optimizer.step()\n","        avg_loss.append(loss.item())\n","        if batch_idx % log_interval == 0:\n","            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n","                                                                           batch_idx * len(data.x),\n","                                                                           len(train_loader.dataset),\n","                                                                           100. * batch_idx / len(train_loader),\n","                                                                           loss.item()))\n","    return sum(avg_loss)/len(avg_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LiQ68BUFv0TR"},"source":["def predicting(model, device, loader):\n","    model.eval()\n","    total_preds = torch.Tensor()\n","    total_labels = torch.Tensor()\n","    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n","    with torch.no_grad():\n","        for data in loader:\n","            data = data.to(device)\n","            output, _ = model(data)\n","            total_preds = torch.cat((total_preds, output.cpu()), 0)\n","            total_labels = torch.cat((total_labels, data.y.view(-1, 2).cpu()), 0)\n","    return total_labels,total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFnbzYVmp4Or"},"source":["# set_parameter_requires_grad(model, feature_extracting=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zitkvistv2zd"},"source":["lr = 0.001\n","num_epoch = 100\n","train_batch = 128\n","val_batch = 128\n","test_batch = 128 \n","log_interval = 20\n","best_ret_test = None\n","print('Learning rate: ', lr)\n","print('Epochs: ', num_epoch)\n","model_st = \"GINConvNetCls\"\n","dataset = 'GDSC'\n","train_losses = []\n","val_losses = []\n","val_pearsons = []\n","print('\\nrunning on ', model_st + '_' + dataset )\n","processed_data_file_train = data_processed_path + dataset + '_train_mix'+'.pt'\n","processed_data_file_val = data_processed_path + dataset + '_val_mix'+'.pt'\n","processed_data_file_test = data_processed_path + dataset + '_test_mix'+'.pt'\n","if ((not os.path.isfile(processed_data_file_train)) or (not os.path.isfile(processed_data_file_val)) or (not os.path.isfile(processed_data_file_test))):\n","    print('please run create_data.py to prepare data in pytorch format!!!!')\n","else:\n","    train_data = TestbedDataset(root=data_path, dataset=dataset+'_train_mix')\n","    val_data = TestbedDataset(root=data_path, dataset=dataset+'_val_mix')\n","    test_data = TestbedDataset(root=data_path, dataset=dataset+'_test_mix')\n","    print(test_data.__dict__)\n","\n","    # make data PyTorch\n","    # mini-batch processing ready\n","    train_loader = DataLoader(train_data, batch_size=train_batch, shuffle=True)\n","    val_loader = DataLoader(val_data, batch_size=val_batch, shuffle=False)\n","    # train_loader = DataLoader(val_data, batch_size=val_batch, shuffle=False)\n","    test_loader = DataLoader(test_data, batch_size=test_batch, shuffle=False)\n","    print(\"CPU/GPU: \", torch.cuda.is_available())\n","            \n","    # training the model\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(device)\n","    bce = nn.BCELoss()\n","    optimizer = torch.optim.Adam(params_to_update, lr=lr)    \n","    best_bce = 1000\n","    best_pearson = 1\n","    best_epoch = -1\n","    model_file_name = 'model_new' + model_st + '_' + dataset +  '.model'\n","    result_file_name = 'result_' + model_st + '_' + dataset +  '.csv'\n","    loss_fig_name = 'model_' + model_st + '_' + dataset + '_loss'\n","    pearson_fig_name = 'model_' + model_st + '_' + dataset + '_pearson'\n","    for epoch in range(num_epoch):\n","        train_loss = train(model, device, train_loader, optimizer, epoch+1, log_interval)\n","        G,P = predicting(model, device, val_loader)\n","        # G,P = predicting(model, device, test_loader)\n","\n","        ret = [roc_auc_score(G,P),bce(G,P),pearson(G,P),spearman(G,P)]\n","                    \n","        G_test,P_test = predicting(model, device, test_loader)\n","        ret_test = [roc_auc_score(G_test,P_test),bce(G_test,P_test),pearson(G_test,P_test),spearman(G_test,P_test)]\n","\n","        train_losses.append(train_loss)\n","        val_losses.append(ret[1])\n","        val_pearsons.append(ret[2])\n","        if ret[1]<best_bce:\n","            torch.save(model.state_dict(), model_file_name)\n","            with open(result_file_name,'w') as f:\n","                f.write(','.join(map(str,ret_test)))\n","            best_epoch = epoch+1\n","            best_bce = ret[1]\n","            best_pearson = ret[2]\n","            best_auc = ret[0]\n","            best_ret_test = ret_test\n","            print(' bce improved at epoch ', best_epoch, '; best_bce:', best_bce,model_st,dataset, \"; best_auc:\", best_auc)\n","        else:\n","            print(' no improvement since epoch ', best_epoch, '; best_bce, best pearson:', best_bce, best_pearson, model_st, dataset, \"; best_auc:\", best_auc)\n","    draw_loss(train_losses, val_losses, loss_fig_name)\n","    draw_pearson(val_pearsons, pearson_fig_name)\n","    print(best_ret_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IPVAlr-NjQLD"},"source":["data_path = \"/content/drive/MyDrive/05.New_DRP3_ge_meth/MOLI/preprocess/processed_ge_mut/\" # data to process\n","pretrain_cls = \"/content/drive/MyDrive/05.New_DRP3_ge_meth/model_newGINConvNetCls_GDSC.model\"\n","model.load_state_dict(torch.load(pretrain_cls))\n","GDSC_Docetaxel_test_mix = TestbedDataset(root=data_path, dataset=\"GDSC_Docetaxel_test_mix\")\n","GDSC_Erlotinib_test_mix = TestbedDataset(root=data_path, dataset=\"GDSC_Erlotinib_test_mix\")\n","GDSC_Gemcitabine_test_mix = TestbedDataset(root=data_path, dataset=\"GDSC_Gemcitabine_test_mix\")\n","GDSC_Paclitaxel_test_mix = TestbedDataset(root=data_path, dataset=\"GDSC_Paclitaxel_test_mix\")\n","\n","GDSC_Docetaxel_test_mix = DataLoader(GDSC_Docetaxel_test_mix, batch_size=test_batch, shuffle=False)\n","GDSC_Erlotinib_test_mix = DataLoader(GDSC_Erlotinib_test_mix, batch_size=test_batch, shuffle=False)\n","GDSC_Gemcitabine_test_mix = DataLoader(GDSC_Gemcitabine_test_mix, batch_size=test_batch, shuffle=False)\n","GDSC_Paclitaxel_test_mix = DataLoader(GDSC_Paclitaxel_test_mix, batch_size=test_batch, shuffle=False)\n","bce = nn.BCELoss()\n","test_loaders = [GDSC_Docetaxel_test_mix, GDSC_Erlotinib_test_mix, GDSC_Gemcitabine_test_mix, GDSC_Paclitaxel_test_mix]\n","for test_loader in test_loaders:\n","  G_test,P_test = predicting(model, device, test_loader)\n","  ret_test = [roc_auc_score(G_test,P_test),bce(G_test,P_test),pearson(G_test,P_test),spearman(G_test,P_test)]\n","  print(ret_test)\n","  print(\"_________________________________________________________________________________________________\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KScEq2VxrlET"},"source":[""],"execution_count":null,"outputs":[]}]}